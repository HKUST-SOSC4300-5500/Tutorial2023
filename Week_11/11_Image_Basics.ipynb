{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67NLL70olGh3"
   },
   "source": [
    "## Vectorization \n",
    "\n",
    "Below is a minimum working procedure to turn an image into a low-dimensional vector using VGG (a widely-studied image processing architecture). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGD7BXhjlL54"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "import keras.utils as image\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "vgg_model = VGG19(include_top = False, weights = 'imagenet', pooling='max', input_shape=(224, 224, 3))\n",
    "# trick here: set include_top = F so that the model can be used for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMwVi1VBycor"
   },
   "source": [
    "Read in image and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCOmd--Xqs9h",
    "outputId": "c5fefa28-bc20-454b-e997-ffd4a1690960"
   },
   "outputs": [],
   "source": [
    "imgpath = \"content/005BHtGojw1f30um7zp9yj30np0hsgnb.jpg\"\n",
    "\n",
    "# read images as pixel representations\n",
    "img = image.load_img(imgpath, target_size = (224, 224, 3))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# add new axis to x; the model expects an input tensor of shape (batch_size, height, width, channels)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "print (x.shape)\n",
    "\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "173hvLoLS60u",
    "outputId": "c21bede9-83a3-4945-d319-f782938ed092"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5fejo6QCP1V"
   },
   "source": [
    "turning this 224 * 224 * 3 input image vector into a 512 dimensinoal vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yT5zHSSSrv2x",
    "outputId": "c3123ccc-bc68-45e3-b6ea-92f01d91998c"
   },
   "outputs": [],
   "source": [
    "features = vgg_model.predict(x)\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53jn8STDr6sZ",
    "outputId": "109ccbd7-64a8-4a24-80e3-acb22e1caf07"
   },
   "outputs": [],
   "source": [
    "flattened_features = features.flatten()\n",
    "normalized_features = flattened_features / norm(flattened_features)\n",
    "print (normalized_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFa7ZU4Qs3hx",
    "outputId": "c3739dbd-7557-4cfd-e2ff-5915cf5ec70f"
   },
   "outputs": [],
   "source": [
    "print (normalized_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSH3SALqcEbK"
   },
   "source": [
    "## Calculate similarity\n",
    "\n",
    "here, we calculate cosine similarities between each pair of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVOwu9nkcDJ5",
    "outputId": "a8ce2fa6-07f6-401e-e686-df297bde3129"
   },
   "outputs": [],
   "source": [
    "## first, get all images ending up with jpg\n",
    "\n",
    "\n",
    "import glob\n",
    "imgs = glob.glob(\"content/*.jpg\") \n",
    "print (imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1zCu6odPconW",
    "outputId": "2e6acb62-18a3-499d-e147-9e5735fef184"
   },
   "outputs": [],
   "source": [
    "## second, calculate pairwise similarity\n",
    "\n",
    "import math\n",
    "def cosine_similarity(v1,v2):\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracted image representation for the first image\n",
    "result_tuple = []\n",
    "\n",
    "img1 = imgs[0]\n",
    "print (img1)\n",
    "\n",
    "img = image.load_img(img1, target_size = (224, 224, 3))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x = preprocess_input(x)\n",
    "features = vgg_model.predict(x)\n",
    "flattened_features = features.flatten()\n",
    "normalized_features1 = flattened_features / norm(flattened_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracted image representation for the second to the last image\n",
    "## and calculate cosine similarity between the first image and each of the rest image\n",
    "\n",
    "for img2 in imgs[1:]:\n",
    "\n",
    "    if img1 == img2:\n",
    "      continue # avoid comparing the same picture\n",
    "    img = image.load_img(img2, target_size = (224, 224, 3))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = preprocess_input(x)\n",
    "    features = vgg_model.predict(x)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features2 = flattened_features / norm(flattened_features)\n",
    "\n",
    "    cos = cosine_similarity(normalized_features1, normalized_features2)\n",
    "    print (img2, cos)\n",
    "\n",
    "    result_tuple.append((img2, cos))\n",
    "\n",
    "import pandas as pd\n",
    "d = pd.DataFrame(result_tuple)\n",
    "d.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmiIWBciuqkw"
   },
   "source": [
    "## Exercise\n",
    "I take a sample of dataset from here \n",
    "https://www.kaggle.com/crowdflower/twitter-user-gender-classification\n",
    "\n",
    "There are two tasks you may explore:\n",
    "\n",
    "- Try a clustering algorithm on the image dataset (`profile_pictures_training`) \n",
    "   - Can you find meaningful clusters?\n",
    "- Try a supervised ML task:\n",
    "   - use images in `profile_pictures_training` train your model. The `training_metadata.csv` contains a `gender` column which is the outcome for training.\n",
    "   - Then predict gender of images in `profile_pictures_test`. Verify your predictions the the gender in `test_metadata.csv`.\n",
    "   - You can use any method, e.g., logistic regression, SVM, random forests, or any other things you know.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbNvdzHFOvKf"
   },
   "source": [
    "If you are not familiar with coding in Python, feel free to save the data to R and download that to your disk and use R.\n",
    "\n",
    "For instance, the below code will save your data to a file \"test.csv\" and then you can download that to your local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wALtFUZMvejI"
   },
   "outputs": [],
   "source": [
    "with open (\"test.csv\", 'w') as w:\n",
    "  for cell in normalized_features:\n",
    "    w.write(f\"{cell},\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiLG-ncgORsR"
   },
   "source": [
    "the below cell is how you upload the material on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDJTpCYm_OM-",
    "outputId": "2b76885f-3bf4-489b-c4aa-af1e26ece22a"
   },
   "outputs": [],
   "source": [
    "!unzip -uq /content/material.zip"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
