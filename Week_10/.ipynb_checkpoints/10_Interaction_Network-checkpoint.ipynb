{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import json\n",
    "\n",
    "#handling plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read json to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information that we've collected is stored in the file 'tweets.txt'. Because this file has a JSON format, we'll take advantage of the `read_json` function of the pandas module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json\n",
    "\n",
    "Official doc: https://www.json.org/json-en.html\n",
    "\n",
    "- A data format designed for data exchange between systems and languages\n",
    "\n",
    "- Essentially a tree-like structure built on two types of structure common in most programming languages (akin to dictionary and list in Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json into a pandas dataframe\n",
    "tweets_df = pd.read_json(\"tweets.txt\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [Twitter API website](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object), the Tweet object retrieved, provided in JSON format, has a long list of mixed `root-level` attributes, including basic information such as `id`, `created_at`, and `text`. Tweet objects are also the `parent` object to several child objects. Tweet child objects include `user`, `entities`, and extended_entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a better idea of the information we are dealing with, let's take a look at the `DataFrame` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the displayed columns, we can observe some of them that look interesting for our future analysis. If we look more in detail, certain columns, such as `retweeted_status`, `entities` provide us with information about interactions regarding user mentions and user retweets. So, we are going to create a new `DataFrame` where to store all this important information that will come in handy when we build our Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['retweeted_status'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second dataframe to put important information\n",
    "tweets_final = pd.DataFrame(columns = [\"created_at\", \"id\", \"in_reply_to_screen_name\", \"in_reply_to_status_id\", \"in_reply_to_user_id\",\n",
    "                                      \"retweeted_id\", \"retweeted_screen_name\", \"user_mentions_screen_name\", \"user_mentions_id\", \n",
    "                                       \"text\", \"user_id\", \"screen_name\", \"followers_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that are going to be the same\n",
    "equal_columns = [\"created_at\", \"id\", \"text\"]\n",
    "tweets_final[equal_columns] = tweets_df[equal_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to obtain important information. There are three types of interactions between two Twitter users that we should gather: retweets, replies, and mentions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the structure of the [JSON file](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json#tweetobject) retrieved by the Twitter API, we learn that we can obtain basic information about the user: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"user\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the basic information about user \n",
    "def get_basics(tweets_final):\n",
    "    tweets_final[\"screen_name\"] = tweets_df[\"user\"].apply(lambda x: x[\"screen_name\"])\n",
    "    tweets_final[\"user_id\"] = tweets_df[\"user\"].apply(lambda x: x[\"id\"])\n",
    "    tweets_final[\"followers_count\"] = tweets_df[\"user\"].apply(lambda x: x[\"followers_count\"])\n",
    "    return tweets_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `entities` object is a dictionary that contains, among other information, the `user_mentions` object that represents other Twitter users (`screen_name` and `id`) mentioned in the text of the Tweet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"entities\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user mentions \n",
    "def get_usermentions(tweets_final):\n",
    "    # Inside the tag 'entities' will find 'user mentions' and will get 'screen name' and 'id'\n",
    "    tweets_final[\"user_mentions_screen_name\"] = tweets_df[\"entities\"].apply(lambda x: x[\"user_mentions\"][0][\"screen_name\"] if x[\"user_mentions\"] else np.nan)\n",
    "    tweets_final[\"user_mentions_id\"] = tweets_df[\"entities\"].apply(lambda x: x[\"user_mentions\"][0][\"id_str\"] if x[\"user_mentions\"] else np.nan)\n",
    "    return tweets_final\n",
    "\n",
    "# Note how lambda function allows for this kind of conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"entities\"][26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tweets_df[\"entities\"][26][\"user_mentions\"]: \n",
    "    print('haha')\n",
    "else:\n",
    "    print('hehe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retweets always contain two Tweet objects: The original Tweet being Retweeted is provided in a `retweeted_status` object. Inside, the `user` object for the account (`screen_name` and `id`) taking the Retweet action and the time of the Retweet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df[\"retweeted_status\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get retweets\n",
    "def get_retweets(tweets_final):\n",
    "    # Inside the tag 'retweeted_status' will find 'user' and will get 'screen name' and 'id'    \n",
    "    tweets_final[\"retweeted_screen_name\"] = tweets_df[\"retweeted_status\"].apply(lambda x: x[\"user\"][\"screen_name\"] if x is not np.nan else np.nan)\n",
    "    tweets_final[\"retweeted_id\"] = tweets_df[\"retweeted_status\"].apply(lambda x: x[\"user\"][\"id_str\"] if x is not np.nan else np.nan)\n",
    "    return tweets_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Tweet object, we can get the information of the user and status to which the tweet replies to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the information about replies\n",
    "def get_in_reply(tweets_final):\n",
    "    # Just copy the 'in_reply' columns to the new dataframe\n",
    "    tweets_final[\"in_reply_to_screen_name\"] = tweets_df[\"in_reply_to_screen_name\"]\n",
    "    tweets_final[\"in_reply_to_status_id\"] = tweets_df[\"in_reply_to_status_id\"]\n",
    "    tweets_final[\"in_reply_to_user_id\"]= tweets_df[\"in_reply_to_user_id\"]\n",
    "    return tweets_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a function that calls all the functions to fill the DataFrame with the usefull variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly fill the new dataframe with the important information\n",
    "def fill_df(tweets_final):\n",
    "    get_basics(tweets_final)\n",
    "    get_usermentions(tweets_final)\n",
    "    get_retweets(tweets_final)\n",
    "    get_in_reply(tweets_final)\n",
    "    return tweets_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fill the DataFrame and discard the None values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final = fill_df(tweets_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware of None values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final = tweets_final.where(pd.notnull(tweets_final), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.notnull(tweets_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creart a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to initialize the Graph. We can do this by calling the function .Graph() of NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two other important functions to create a Graph. The first one is add_node()and the second one, add_edge both with a very descriptive name. Let's pay attention to the syntax of add_edge:  \n",
    "\n",
    "`Graph.add_edge(u_of_edge, v_of_edge, **attr)`  \n",
    "\n",
    "where `u`, `v` are the nodes, and attr are keyword arguments that characterize the edge data such as weight, capacity, length, etc.\n",
    "  \n",
    "If we add an edge that already exists, the edge data will get updated. Also, if we are an edge between two nodes that are still not in the Graph, the nodes will be created in the process.\n",
    "\n",
    "We are going to populate the Graph by creating a function `get_interactions`. With this information, we apply the function add_edge to every tuple consisting of the tweet's user_id and the user_id of the user mentioned, replied to or retweeted, creating the nodes and the edges connecting them. Also, the tweet id will be added as edge data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the interactions between the different users\n",
    "def get_interactions(row):\n",
    "    # For each row of the original dataframe\n",
    "    # First we obtain the 'user_id' and 'screen_name'\n",
    "    user = row[\"user_id\"], row[\"screen_name\"]\n",
    "    # Be careful if there is no user id\n",
    "    if user[0] is None:\n",
    "        return (None, None), []\n",
    "    \n",
    "    # The interactions are going to be a set of tuples\n",
    "    interactions = set()\n",
    "    # Add all interactions — Note here we don't distinguish different kinds of interactions. \n",
    "    # First, we add the interactions corresponding to replies adding the id and screen_name\n",
    "    interactions.add((row[\"in_reply_to_user_id\"], row[\"in_reply_to_screen_name\"]))\n",
    "    # After that, we add the interactions with retweets\n",
    "    interactions.add((row[\"retweeted_id\"], row[\"retweeted_screen_name\"]))\n",
    "    # And later, the interactions with user mentions\n",
    "    interactions.add((row[\"user_mentions_id\"], row[\"user_mentions_screen_name\"]))\n",
    "    \n",
    "    # Discard if user id is in interactions\n",
    "    interactions.discard((row[\"user_id\"], row[\"screen_name\"]))\n",
    "    # Discard all not existing values\n",
    "    interactions.discard((None, None))\n",
    "    # Return user and interactions\n",
    "    return user, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in tweets_final.iterrows():\n",
    "    user, interactions = get_interactions(tweet)\n",
    "    user_id, user_name = user\n",
    "    tweet_id = tweet[\"id\"]\n",
    "    \n",
    "    for interaction in interactions:\n",
    "        int_id, int_name = interaction\n",
    "        graph.add_edge(user_id, int_id, tweet_id=tweet_id)\n",
    "        graph.nodes[user_id][\"name\"] = user_name\n",
    "        graph.nodes[int_id][\"name\"] = int_name       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the node and edge of the Graph created, let's see the number of nodes and edges present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges present in the Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree of a node u, denoted as deg(u), is the number of edges that occur to that node. In simpler words, the number of connections a particular node has. The maximum degree of a graph and the minimum degree of a graph are the maximum and minimum degree of its nodes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [val for (node, val) in graph.degree()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The maximum degree of the Graph is {np.max(degrees)}\")   \n",
    "print(f\"The minimum degree of the Graph is {np.min(degrees)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average degree of the nodes in the Graph is {np.mean(degrees):.1f}\")  \n",
    "print(f\"The most frequent degree of the nodes found in the Graph is {sp.stats.mode(degrees)[0][0]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An undirected graph is connected if, for every pair of nodes, there is a path between them. For that to happen, most of the nodes should have at least a degree of two, except for those denominated leaves which have a degree of 1. From the characteristics of the Graph, we can suspect that the graph is not connected. In order to confirm these, we can use `nx.is_connected`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nx.is_connected(graph):\n",
    "    print(\"The graph is connected\")\n",
    "else:\n",
    "    print(\"The graph is not connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we confirm that our Graph is not connected, we can check how many connected components it has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {nx.number_connected_components(graph)} connected components in the Graph\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_subgraph = max((graph.subgraph(c) for c in nx.connected_components(graph)), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {largest_subgraph.number_of_nodes()} nodes and {largest_subgraph.number_of_edges()} \\\n",
    "edges present in the largest component of the Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nx.is_connected(largest_subgraph):\n",
    "    print(\"The graph is connected\")\n",
    "else:\n",
    "    print(\"The graph is not connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering and transitivity measure the tendency for nodes to cluster together or for edges to form triangles. In our context, they are measures of the extent to which the users interacting with one particular user tend to interact with each other as well. The difference is that transitivity weights nodes with a large degree higher. \n",
    "The clustering coefficient, a measure of the number of triangles in a graph, is calculated as the number of triangles connected to node i divided by the number of sets of two edges connected to node i (Triple nodes). While the transitivity coefficient is calculated as 3 multiply by the number of triangles in the network divided by the number of connected triples of nodes in the network. These two parameters are very important when analyzing social networks because it gives us an insight into how users tend to create tightly knot groups characterized by relatively high-dense ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average clustering coefficient is {nx.average_clustering(largest_subgraph)} in the largest subgraph\")\n",
    "print(f\"The transitivity of the largest subgraph is {nx.transitivity(largest_subgraph)}\")\n",
    "\n",
    "# Not a very dense network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to focus on **network centrality** which captures the importance of a node's position in the network considering: degree on the assumption that an important node will have many connections, closeness on the assumption that important nodes are close to other nodes, and finally, betweenness on the assumption that important nodes are well situated and connect other nodes. Here we try `degree_centrality` and capture the node with the best score in each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_centrality = nx.degree_centrality(largest_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_de = max(graph_centrality.items(), key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the node with id {max_de[0]} has a degree centrality of {max_de[1]:.2f} which is the maximum of the Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we can see how the network graph looks like. \n",
    "\n",
    "- We will use nx.drawing.layout with node positioning algorithms for drawing network graph. \n",
    "\n",
    "    - Use spring_layout that uses force-directed graph drawing which purpose is to position the nodes in two-dimensional space so that all the edges are of equal length and as few crossing edges as possible. \n",
    "    - It achieves this by assigning forces among the set of edges and nodes based on their relative positions and then uses this to simulate the motion of the edges and nodes. One of the parameters that we can adjust is k, the optimal distance between nodes; as we increase the value, the nodes will farther apart.  Once, that we got the positions, we are also going to create a special list so that we can draw the two nodes with higher centrality that we found in different colors to highlight them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_and_degree = largest_subgraph.degree()\n",
    "colors_central_nodes = ['orange','red']\n",
    "central_nodes = ['25073877','39344374']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(largest_subgraph, k=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the functions `.draw_networkx_nodes()` and `.draw()` to show the largest connected component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "\n",
    "nx.draw(largest_subgraph, pos=pos, node_color='grey', cmap=plt.cm.PiYG, edge_color=\"black\", linewidths=0.3, node_size=60, alpha=0.6, with_labels=False)\n",
    "nx.draw_networkx_nodes(largest_subgraph, pos=pos, nodelist=central_nodes, node_size=300, node_color=colors_central_nodes)\n",
    "\n",
    "plt.savefig('graphfinal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
